{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd80250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from datasets import load_dataset\n",
    "import cassio\n",
    "from PyPDF2 import PdfReader\n",
    "from typing_extensions import Concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f5fc5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # This will look for a .env file in the current directory\n",
    "\n",
    "ASTRA_DB_APPLICATION_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "ASTRA_DB_ID = os.getenv(\"ASTRA_DB_ID\")\n",
    "GROQ_TOKEN = os.getenv(\"GROQ_TOKEN\")\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f34f7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "llm=ChatGroq(groq_api_key=GROQ_TOKEN,model_name='llama-3.1-8b-instant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e964e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfreader = PdfReader('data/sr117.pdf')\n",
    "# read text from pdf\n",
    "raw_text = ''\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9448aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "527d4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_store = Cassandra(\n",
    "    embedding=embedding,\n",
    "    table_name=\"mrm_policy\",\n",
    "    session=None,\n",
    "    keyspace=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30fee7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce99c5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 115 headlines.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "astra_vector_store.add_texts(texts)\n",
    "\n",
    "print(\"Inserted %i headlines.\" % len(texts))\n",
    "\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b763163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: \"In IRC model, what is the simulation horizon\"\n",
      "ANSWER: \"The simulation horizon in an IRC (Internal Ratings-Based) model is not explicitly mentioned in the provided context. However, it is implied that the model is built for a one-year capital horizon (mentioned in points 2, 15, and 16), which aligns with the 99.9 percent soundness standard over a one-year capital horizon as described in the Basel II Framework.\n",
      "\n",
      "If you are looking for more information on the simulation horizon in an IRC model, I would recommend consulting the Basel II Framework or other relevant regulatory documents for more detailed information.\"\n",
      "\n",
      "FIRST DOCUMENTS BY RELEVANCE:\n",
      "    [0.7883] \"14. As described immediately below, for each IRC-covered position the model should \n",
      "also capture the impact of rebalancing positions at  the end of their liquidity horizons so as to \n",
      "achieve a constant level of risk over a one- year capital horizon. The model may incorporate \n",
      "correlation effects among the modelled risk factors, subject to validation standards set forth \n",
      "in Section III. The trading portfolio’s IRC equals the IRC model’s estimate of losses at the \n",
      "99.9 percent confidence level. \n",
      "2. Constant level of risk over one-year capital horizon \n",
      "15. An IRC model should be based on the assumption of a constant level of risk over \n",
      "the one-year capital horizon.\n",
      "3 \n",
      "16. This constant level of risk assumption implies that a bank rebalances, or rolls over, ...\"\n",
      "    [0.7812] \"trading books. Since the Basel II Framework reflects a 99.9 percent soundness standard \n",
      "over a one-year capital horizon, the IRC is also described in these terms.  \n",
      "13. Specifically, for all IRC-covered positions, a bank’s IRC model must measure losses \n",
      "due to default and migration at the 99.9 percent confidence interval over a capital horizon of one year, taking into account the liquidity horizons applicable to individual trading positions or sets of positions. Losses caused by broader market-wide events affecting multiple issues/issuers are encompassed by this definition. \n",
      "14. As described immediately below, for each IRC-covered position the model should \n",
      "also capture the impact of rebalancing positions at  the end of their liquidity horizons so as to ...\"\n",
      "    [0.7429] \"(eg backtesting requirements) allows the use of relatively short data windows for estimating VaR parameters (as short as one year), which can produce insufficient required capital against trading positions following periods of relative calm in financial markets. \n",
      "3. As described in more detail below, the IRC represents an estimate of the default and \n",
      "migration risks of unsecuritised credit products over a one-year capital horizon at a 99.9 percent confidence level, taking into account the liquidity horizons of individual positions or \n",
      "sets of positions. The Committee expects banks to develop their own models for calculating ...\"\n",
      "    [0.7329] \"7. The remainder of this paper is structured as follows: \n",
      "• Section II sets forth the scope of the IRC and principles underlying the construction \n",
      "of IRC models. \n",
      "• Section III discusses the validation of IRC models. \n",
      "• Section IV specifies ways in which the results of banks’ internal risk measurement \n",
      "models can be used as the foundation for an IRC. \n",
      "II. Principles for calculating the IRC \n",
      "A. IRC-covered positions and risks \n",
      "8. According to paragraph 718(xcii) of the Basel II Framework, the IRC encompasses \n",
      "all positions subject to a capital charge for specific interest rate risk according to the internal \n",
      "models approach to specific market risk but not subject to the treatment outlined in paragraphs 712(iii) to 712(vii) of the Basel II Framework, regardless of their perceived ...\"\n"
     ]
    }
   ],
   "source": [
    "first_question = True\n",
    "while True:\n",
    "    if first_question:\n",
    "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
    "    else:\n",
    "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
    "\n",
    "    if query_text.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    if query_text == \"\":\n",
    "        continue\n",
    "\n",
    "    first_question = False\n",
    "\n",
    "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
    "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
    "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
    "\n",
    "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
    "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179fafa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
